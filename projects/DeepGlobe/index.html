<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> DeepGlobe Land Cover Classification | Hrishi </title> <meta name="author" content="Hrishikesh Singh"> <meta name="description" content="Classifying land coverage using remote sensing satelite data."> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8C%90&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://hrishikeshh.github.io/projects/DeepGlobe/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Hrishi </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">Projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/summaries/">ML Paper Summaries </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Notes </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">DeepGlobe Land Cover Classification</h1> <p class="post-description">Classifying land coverage using remote sensing satelite data.</p> </header> <article> <blockquote> <p>Code: <a href="https://github.com/hrishikeshh/DeepGlobe-Land-Cover-Classification" rel="external nofollow noopener" target="_blank">GitHub Repo</a></p> </blockquote> <hr> <h2 id="1-background">1. Background</h2> <blockquote> <p>This project presumes some prior high level understanding of machine learning, deep neural networks, and working in Python, Keras, and TensorFlow 2.0.</p> </blockquote> <p><strong>Satellite Imagery</strong>: Satellite and remote sensing have seen great advances in recent years with one of the key catalyst being the price compression in launch costs from private space launch companies. This has allowed a wider cast of entities and organizations to deploy more satellites. The quality of imagery available to the general public, such as those from Sentinel-2, is also increasing; although still a ways from privately paid satellite services. Sentinel-2 has a typical pixel resolution of 10m band which means that each pixel represents 10m x 10m area.</p> <p><strong>CNNs</strong>: Convolutional Neural Networks are the state of the art neural network architecture for image recognition and computer vision tasks. There are many different variations of CNNs but they typically consist of convolution, pooling, and dense connected layers. CNNs perform much better than regular feed-forward neural networks in images due to its ability to reduce the resolution (dimensions) of an image onto feature maps while still encoding the key features of that image. This greatly reduces the complexity and computational need of the network. A typical CNN architecture is shown below.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/deepglobe/cnn-structure.webp-480.webp 480w,/assets/img/deepglobe/cnn-structure.webp-800.webp 800w,/assets/img/deepglobe/cnn-structure.webp-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/deepglobe/cnn-structure.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Typical structure of CNN" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> A typical Convolutional Neural Network. Source: HML </div> <p><strong>FCNs</strong>: Typical CNNs perform great for classifying entire images but have difficulty classifying objects and segments within images. This is due to the fact that the convolution and pooling layers essentially encode the key features of the image down into ever smaller feature maps then feed that into fully connected layers, before a final Sigmoid or Softmax activation layer for final classification. The encoded features or final classifications cannot be easily mapped back to the original image.</p> <p>This is where <em>Long et al. (2015)’s Fully Convolutional Network (FCN)</em> come in. FCNs are just like CNNs except they have a series of convolutional and upsampling layers to mirror the convolutional and pooling layers in place of the dense connected layers. This allows the network to encode (downsample) and then decode (upsample) back into the original image’s resolution and spatial dimensions which allow for pixel-wise classification. If we edit the typical CNN layer from earlier, we might reach a configuration of something that looks like below.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/deepglobe/cnn-int.webp-480.webp 480w,/assets/img/deepglobe/cnn-int.webp-800.webp 800w,/assets/img/deepglobe/cnn-int.webp-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/deepglobe/cnn-int.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="CNN" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Fig: What a Fully Convolutional Network might look like. Note that this is not a true FCN but helps in gaining some intuition into the how and why. Source: HML </div> <p><strong>Common Types of Computer Vision Problems:</strong> For this project, I will be working with a type of computer vision problem called <strong>semantic segmentation</strong>. There are many other types of problem sets like object detection, instance segmentation, and others which warrant their own discussions at a later date.</p> <p>Semantic Segmentation is determining which pixels in an image belongs to which class as shown below. For these problems, pixel-wise classification and localization of objects and edges within an image are important and therefore are good uses of FCNs.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/deepglobe/segmentation.webp-480.webp 480w,/assets/img/deepglobe/segmentation.webp-800.webp 800w,/assets/img/deepglobe/segmentation.webp-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/deepglobe/segmentation.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="segmentation" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Fig: Semantic Segmentation Example. Source: Jeremy Jordan </div> <h2 id="2-dataset">2. Dataset</h2> <blockquote> <p>The <a href="https://competitions.codalab.org/competitions/18468" rel="external nofollow noopener" target="_blank">DeepGlobe Land Cover Classification Challenge</a> and hence, the dataset are governed by <a href="http://deepglobe.org/docs/DeepGlobe_Rules_3_2.pdf" rel="external nofollow noopener" target="_blank">DeepGlobe Rules</a>, The <a href="http://deepglobe.org/docs/CVPR_InternalUseLicenseAgreement_07-11-18.pdf" rel="external nofollow noopener" target="_blank">DigitalGlobe’s Internal Use License Agreement</a>, and <a href="http://deepglobe.org/docs/Annotation%20License%20Agreement.pdf" rel="external nofollow noopener" target="_blank">Annotation License Agreement</a>.</p> </blockquote> <blockquote> <p>Data Source : <a href="https://competitions.codalab.org/competitions/18468" rel="external nofollow noopener" target="_blank">DeepGlobe Land Cover Classification</a></p> </blockquote> <p><strong>Training Data</strong>: The dataset comprised of <strong>803 satellite imagery</strong> in RGB of size <strong>2448x2448</strong> with one set comprised of satellite images and the other set comprised of labeled masks. Each satellite image is at the 50cm pixel resolution band collected by DigitalGlobe’s satellite. 50cm pixel resolution is quite high by typical publicly accessible satellite imagery resolution standards which are usually around the 5m to 10m pixel resolution band.</p> <p><strong>Test Data:</strong> The dataset also contained <strong>171 validation</strong> and <strong>172 test images</strong>, both without labeled masks. I ended up combining these 2 groups into a testing dataset and randomly sampled a subset of the training data for validation.</p> <p>Here are some sample training images:</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/deepglobe/sample-img.webp-480.webp 480w,/assets/img/deepglobe/sample-img.webp-800.webp 800w,/assets/img/deepglobe/sample-img.webp-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/deepglobe/sample-img.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Sample data" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Fig: Sample of 8 training satellite images and their corresponding Ground Truth Mask labels. </div> <p>Each satellite image can have up to 7 different segmentation classes where each class is denoted by a different color in the Ground Truth Mask labels. The table below shows the seven different classes, their RGB channel values, and associated color in the Ground Truth Mask labels.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/deepglobe/table.webp-480.webp 480w,/assets/img/deepglobe/table.webp-800.webp 800w,/assets/img/deepglobe/table.webp-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/deepglobe/table.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="table" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Fig: Breakdown of the 7 segmentation classes. </div> <h2 id="3-neural-network-architectures">3. Neural Network Architectures</h2> <p>After some research and testing, I settled on implementing two different network architectures for my problem set.</p> <h3 id="u-net">U-Net</h3> <p>The first network architecture is <a href="https://arxiv.org/abs/1505.04597" rel="external nofollow noopener" target="_blank">Ronneberger et al. (2015)’s U-Net</a>. The U-Net was originally developed for segmenting biomedical images but have since then been widely used for segmenting many types of images by the ML community. The architecture is shown below where the convolutional and max pooling layers perform an encoder operation on the image and the convolutional and upsampling layers perform the corresponding decoder operation into a full resolution output segmentation map. It also implements long skip connections (grey arrows) which concatenate feature maps from correspondingly sized layers in the encoder and decoder layers to help with localization of objects and edges within the image.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/deepglobe/u-net.webp-480.webp 480w,/assets/img/deepglobe/u-net.webp-800.webp 800w,/assets/img/deepglobe/u-net.webp-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/deepglobe/u-net.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="table" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Fig: Original U-Net architecture. Source: Ronneberger et al. (2015)’s U-Net </div> <h3 id="u-net-with-resnet50-encoder-backbone">U-Net with ResNet50 Encoder Backbone</h3> <p>The second architecture uses transfer learning of a ResNet50 architecture trained on ImageNet to replace the encoder portion of the U-Net. An example of what such an architecture may look like is shown below. In theory, such an architecture can have good performance since it would already be trained on high level features in images from ImageNet and could reduce the amount of training needed than an entirely new untrained architecture.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/deepglobe/u-net-2.webp-480.webp 480w,/assets/img/deepglobe/u-net-2.webp-800.webp 800w,/assets/img/deepglobe/u-net-2.webp-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/deepglobe/u-net-2.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="table" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Fig: Sample ResNet50 encoder and U-Net decoder architecture. Source: Neven, Robby &amp; Goedemé, Toon </div> <h2 id="4-code">4. Code</h2> <p>I will just go over some of the key steps and reasoning in my code process but the code for the entire project and how to set it up can be found in my <a href="https://github.com/hrishikeshh/DeepGlobe-Land-Cover-Classification" rel="external nofollow noopener" target="_blank">GitHub Repo</a>. I chose to use Google Colab to take advantage of their GPUs for training. I developed the neural networks in Keras and TensorFlow 2.0 building on inspiration from <a href="https://github.com/zizhaozhang/unet-tensorflow-keras/blob/master/model.py" rel="external nofollow noopener" target="_blank">Zizhaozhang’s U-Net</a> and <a href="https://github.com/nikhilroxtomar/Semantic-Segmentation-Architecture/blob/main/TensorFlow/resnet50_unet.py" rel="external nofollow noopener" target="_blank">Nikhilroxtomar’s ResNet_U-Net</a> implementations.</p> <h3 id="preprocessing">Preprocessing</h3> <p>The masks first need to be One-Hot Encoded from RGB channels into their respective channels per class like shown in the image below.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/deepglobe/hot-encode.webp-480.webp 480w,/assets/img/deepglobe/hot-encode.webp-800.webp 800w,/assets/img/deepglobe/hot-encode.webp-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/deepglobe/hot-encode.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="table" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Fig: One-Hot Encode of masking images for semantic segmentation. Source: Jeremy Jordan </div> <p>Since each image was 2448x2448x3 and the corresponding masks are 2448x2448x7 (each channel per class), each training sample are quite large so I had to cut them into smaller patches of 612x612 instead.</p> <p>We also needed a custom data generator to yield an, or batches of, image(s) during training instead of loading all training dataset into RAM all at once.</p> <h3 id="training">Training</h3> <p>During training, our metric and loss functions are the Dice Coefficient and Dice Coefficient Loss respectively.To get a better understanding of how the U-Net is built and trained and for the second ResNet50_U-Net transfer learning model implementation please see the GitHub repo.</p> <h2 id="5-results">5. Results</h2> <p>After training, the ResNet50_U-Net had a validation dice coefficient of 0.803 and the U-Net had a dice coefficient of 0.784.</p> <p>Here were some of the validation results showing the original satellite image, the Ground Truth Mask, the predicted Mask from the RestNet50_U-Net architecture, and the predicted Mask from the U-Net architecture. The smaller squares below the initial first level show the activations of each of the 7 classes for the RestNet50_U-Net architecture.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/deepglobe/result-1.webp-480.webp 480w,/assets/img/deepglobe/result-1.webp-800.webp 800w,/assets/img/deepglobe/result-1.webp-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/deepglobe/result-1.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="table" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Fig: Sample results comparing Original Satellite Image, Ground Truth Mask, Predicted ResNet50_U-Net Model, and Predicted U-Net Model (top). Class activations for each of the 7 classes for the RestNet50_U-Net architecture (bottom). </div> <p>Here are a couple of just the U-Net architecture.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/deepglobe/result-2.webp-480.webp 480w,/assets/img/deepglobe/result-2.webp-800.webp 800w,/assets/img/deepglobe/result-2.webp-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/deepglobe/result-2.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="table" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Fig: Sample results comparing Original Satellite Image, Ground Truth Mask, and Predicted U-Net Model (top). Class activations for each of the 7 classes for the U-Net architecture (bottom). </div> <h2 id="6-final-thoughts">6. Final Thoughts</h2> <p>I hope that sharing this post and the source code can help others in the future whom may need it as reference for similar problem sets.</p> <p>One area of improvement for this project would be to try using an architecture specifically designed and pre-trained on semantic segmentation tasks for transfer learning instead of using the ResNet50 which is typically used for multi-class image classifications. Additionally, variations of DeepLab introduced by Chen et al. in Rethinking Atrous Convolution for Semantic Image Segmentation⁷ have found to perform extremely well on image segmentation tasks. It may bode well to give the DeepLabv3 architecture a try.</p> <p>Lastly, I would like to apply the knowledge gained here to more specific problems in the climate and sustainability domain like:</p> <ul> <li>Forest and tree mapping to monitor deforestation</li> <li>Ice-cap monitoring</li> <li>Smart city/urban planning</li> <li>Endangered wildlife monitoring</li> </ul> <hr> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Hrishikesh Singh. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script> </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let theme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===theme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=document.querySelector(".navbar-collapse");e.classList.contains("show")&&e.classList.remove("show"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"Publications",description:"Papers under review/submission and pre-prints are available upon request.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"Projects",description:"",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-ml-paper-summaries",title:"ML Paper Summaries",description:"",section:"Navigation",handler:()=>{window.location.href="/summaries/"}},{id:"nav-cv",title:"CV",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"nav-notes",title:"Notes",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"post-sample-test",title:"Sample Test",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/sample/"}},{id:"post-reading",title:"Reading",description:"A personal reading list.",section:"Posts",handler:()=>{window.location.href="/blog/2024/library/"}},{id:"post-research-my-two-cents",title:"Research: My two cents",description:"These are the nuggets of wisdom I found in the corners of internet while doing my own stint of research. Enjoy.",section:"Posts",handler:()=>{window.location.href="/blog/2024/research/"}},{id:"post-how-to-write-a-review-paper",title:"How to write a review paper?",description:"A walk through guide for structuring your research",section:"Posts",handler:()=>{window.location.href="/blog/2024/review-paper/"}},{id:"post-dsa-templates-java",title:"DSA templates (Java)",description:"These are java code templates based on most common datastructures and algorithm problems.",section:"Posts",handler:()=>{window.location.href="/blog/2024/java-template/"}},{id:"post-pythonic-templates",title:"Pythonic Templates",description:"A collection of code templates for common patterns in data structures and algorithms",section:"Posts",handler:()=>{window.location.href="/blog/2024/python-template/"}},{id:"post-dynamic-programming",title:"Dynamic Programming",description:"Setting up the foundations of Dynamic programming along with a generic framework to disintegrate the problem into components",section:"Posts",handler:()=>{window.location.href="/blog/2024/dynamic-prog/"}},{id:"post-deep-learning",title:"Deep Learning",description:"A curated list of resources for a comprehensive understanding of deep learning.  ",section:"Posts",handler:()=>{window.location.href="/blog/2024/deep-learning/"}},{id:"post-the-beauty-of-latex",title:"The Beauty of LaTeX",description:"When was the first time you had to use LaTeX? If you are like most people, it was probably suddenly forced upon you during your first math or CS class where you had to start writing proofs, with minimal guidance on how to get started. Unfortunately, this meant that while many people have good operational knowledge of LaTeX, there are still many small mistakes and best practices which are not followed, which are not corrected by TAs as they are either not severe enough to warrant a note, or perhaps even the TAs themselves are not aware of them.  In this post, we cover some common mistakes that are made by LaTeX practitioners (even in heavily cited papers), and how to address them.",section:"Posts",handler:()=>{window.location.href="/blog/2023/latex/"}},{id:"post-java-collections",title:"Java Collections",description:"A brief reference for Java collections usecases.",section:"Posts",handler:()=>{window.location.href="/blog/2023/java-collection/"}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"posts-java-collections",title:"Java Collections",description:"A brief reference for Java collections usecases.",section:"Posts",handler:()=>{window.location.href="/blog/2023/java-collection/"}},{id:"posts-the-beauty-of-latex",title:"The Beauty of LaTeX",description:"When was the first time you had to use LaTeX? If you are like most people, it was probably suddenly forced upon you during your first math or CS class where you had to start writing proofs, with minimal guidance on how to get started. Unfortunately, this meant that while many people have good operational knowledge of LaTeX, there are still many small mistakes and best practices which are not followed, which are not corrected by TAs as they are either not severe enough to warrant a note, or perhaps even the TAs themselves are not aware of them.  In this post, we cover some common mistakes that are made by LaTeX practitioners (even in heavily cited papers), and how to address them.",section:"Posts",handler:()=>{window.location.href="/blog/2023/latex/"}},{id:"posts-deep-learning",title:"Deep Learning",description:"A curated list of resources for a comprehensive understanding of deep learning.  ",section:"Posts",handler:()=>{window.location.href="/blog/2024/deep-learning/"}},{id:"posts-dynamic-programming",title:"Dynamic Programming",description:"Setting up the foundations of Dynamic programming along with a generic framework to disintegrate the problem into components",section:"Posts",handler:()=>{window.location.href="/blog/2024/dynamic-prog/"}},{id:"posts-pythonic-templates",title:"Pythonic Templates",description:"A collection of code templates for common patterns in data structures and algorithms",section:"Posts",handler:()=>{window.location.href="/blog/2024/python-template/"}},{id:"posts-dsa-templates-java",title:"DSA templates (Java)",description:"These are java code templates based on most common datastructures and algorithm problems.",section:"Posts",handler:()=>{window.location.href="/blog/2024/java-template/"}},{id:"posts-how-to-write-a-review-paper",title:"How to write a review paper?",description:"A walk through guide for structuring your research",section:"Posts",handler:()=>{window.location.href="/blog/2024/review-paper/"}},{id:"posts-research-my-two-cents",title:"Research: My two cents",description:"These are the nuggets of wisdom I found in the corners of internet while doing my own stint of research. Enjoy.",section:"Posts",handler:()=>{window.location.href="/blog/2024/research/"}},{id:"posts-reading",title:"Reading",description:"A personal reading list.",section:"Posts",handler:()=>{window.location.href="/blog/2024/library/"}},{id:"posts-sample-test",title:"Sample Test",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/sample/"}},{id:"projects-deepglobe-land-cover-classification",title:"DeepGlobe Land Cover Classification",description:"Classifying land coverage using remote sensing satelite data.",section:"Projects",handler:()=>{window.location.href="/projects/DeepGlobe/"}},{id:"projects-gitlet",title:"GitLet",description:"A version control with core functionalities of git, written in Java.",section:"Projects",handler:()=>{window.location.href="/projects/GitLet/"}},{id:"projects-blight-detection",title:"Blight Detection",description:"Assisting the farmers by potato blight grade detection.",section:"Projects",handler:()=>{window.location.href="/projects/blight/"}},{id:"projects-driver-drowsiness-detection-system",title:"Driver Drowsiness Detection System",description:"Determining the distracted or drowsiness state of drivers based on live facial features.",section:"Projects",handler:()=>{window.location.href="/projects/ddds/"}},{id:"projects-classifier-from-scratch",title:"Classifier from Scratch",description:"Designing a linear classifier from scratch.",section:"Projects",handler:()=>{window.location.href="/projects/lin-class/"}},{id:"projects-market-orderbook",title:"Market Orderbook",description:"Simulation",section:"Projects",handler:()=>{window.location.href="/projects/market/"}},{id:"projects-know-your-rice",title:"Know your Rice \ud83c\udf5a",description:"Rice classification using Deep learning.",section:"Projects",handler:()=>{window.location.href="/projects/rice/"}},{id:"projects-vinci",title:"Vinci",description:"A Java Genetic Algorithm implementation with a focus on ease of use and extensibility.",section:"Projects",handler:()=>{window.location.href="/projects/vinci/"}},{id:"summaries-deep-contextualized-word-representations-elmo",title:"Deep contextualized word representations (ELMo)",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-02-deep-contextualized-word-representations/"}},{id:"summaries-foundations-and-trends-in-multimodal-machine-learning-principles-challenges-and-open-questions",title:"Foundations and Trends in Multimodal Machine Learning: Principles,  Challenges, and Open Questions",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-02-foundations-and-trends-in-multimodal-machine-learning-principles--challenges-and-open-questions/"}},{id:"summaries-bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding",title:"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-03-bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding/"}},{id:"summaries-chain-of-thought-prompting-elicits-reasoning-in-large-language-models",title:"Chain-of-Thought Prompting Elicits Reasoning in Large Language Models",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-03-chain-of-thought-prompting-elicits-reasoning-in-large-language-models/"}},{id:"summaries-training-language-models-to-follow-instructions-with-human-feedback-instructgpt",title:"Training language models to follow instructions with human feedback (InstructGPT)",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-05-training-language-models-to-follow-instructions-with-human-feedback/"}},{id:"summaries-evaluating-large-language-models-trained-on-code-codex",title:"Evaluating Large Language Models Trained on Code (Codex)",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-06-evaluating-large-language-models-trained-on-code/"}},{id:"summaries-bart-denoising-sequence-to-sequence-pre-training-for-natural-language-generation-translation-and-comprehension",title:"BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-09-bart-denoising-sequence-to-sequence-pre-training-for-natural-language-generation-translation-and-comprehension/"}},{id:"summaries-dense-passage-retrieval-for-open-domain-question-answering",title:"Dense Passage Retrieval for Open-Domain Question Answering",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-10-dense-passage-retrieval-for-open-domain-question-answering/"}},{id:"summaries-language-models-are-unsupervised-multitask-learners-gpt-2",title:"Language Models are Unsupervised Multitask Learners (GPT-2)",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-10-language-models-are-unsupervised-multitask-learners/"}},{id:"summaries-simple-synthetic-data-reduces-sycophancy-in-large-language-models",title:"Simple synthetic data reduces sycophancy in large language models",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-10-simple-synthetic-data-reduces-sycophancy-in-large-language-models/"}},{id:"summaries-generative-agents-interactive-simulacra-of-human-behavior",title:"Generative Agents: Interactive Simulacra of Human Behavior",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-11-generative-agents-interactive-simulacra-of-human-behavior/"}},{id:"summaries-improving-language-understanding-by-generative-pre-training-gpt",title:"Improving Language Understanding by Generative Pre-Training (GPT)",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-11-improving-language-understanding-by-generative-pre-training/"}},{id:"summaries-metagpt-meta-programming-for-multi-agent-collaborative-framework",title:"MetaGPT: Meta Programming for Multi-Agent Collaborative Framework",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-11-metagpt-meta-programming-for-multi-agent-collaborative-framework/"}},{id:"summaries-transformers-in-speech-processing-a-survey",title:"Transformers in Speech Processing: A Survey",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-19-transformers-in-speech-processing-a-survey/"}},{id:"summaries-accurate-detection-of-wake-word-start-and-end-using-a-cnn",title:"Accurate Detection of Wake Word Start and End Using a CNN",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-22-accurate-detection-of-wake-word-start-and-end-using-a-cnn/"}},{id:"summaries-exploring-the-limits-of-transfer-learning-with-a-unified-text-to-text-transformer",title:"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-22-exploring-the-limits-of-transfer-learning-with-a-unified-text-to-text-transformer/"}},{id:"summaries-efficiently-modeling-long-sequences-with-structured-state-spaces",title:"Efficiently Modeling Long Sequences with Structured State Spaces",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-25-efficiently-modeling-long-sequences-with-structured-state-spaces/"}},{id:"summaries-a-watermark-for-large-language-models",title:"A Watermark for Large Language Models",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-27-a-watermark-for-large-language-models/"}},{id:"summaries-extracting-training-data-from-large-language-models",title:"Extracting Training Data from Large Language Models",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-29-extracting-training-data-from-large-language-models/"}},{id:"summaries-loss-landscapes-and-optimization-in-over-parameterized-non-linear-systems-and-neural-networks",title:"Loss Landscapes and Optimization in Over-Parameterized Non-Linear Systems and Neural Networks",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-09-04-loss-landscapes-and-optimization-in-over-parameterized-non-linear-systems-and-neural-networks/"}},{id:"summaries-gradient-descent-provably-optimizes-over-parameterized-neural-networks",title:"Gradient Descent Provably Optimizes Over-parameterized Neural Networks",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-09-07-gradient-descent-provably-optimizes-over-parameterized-neural-networks/"}},{id:"summaries-the-implicit-bias-of-gradient-descent-on-separable-data",title:"The Implicit Bias of Gradient Descent on Separable Data",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-09-09-the-implicit-bias-of-gradient-descent-on-separable-data/"}},{id:"summaries-understanding-deep-learning-requires-rethinking-generalization",title:"Understanding Deep Learning Requires Rethinking Generalization",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-09-10-understanding-deep-learning-requires-rethinking-generalization/"}},{id:"summaries-calibrate-before-use-improving-few-shot-performance-of-language-models",title:"Calibrate Before Use: Improving Few-Shot Performance of Language Models",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-09-23-calibrate-before-use-improving-few-shot-performance-of-language-models/"}},{id:"summaries-rethinking-the-role-of-demonstrations-what-makes-in-context-learning-work",title:"Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-09-24-rethinking-the-role-of-demonstrations-what-makes-in-context-learning-work/"}},{id:"summaries-repository-level-prompt-generation-for-large-language-models-of-code",title:"Repository-Level Prompt Generation for Large Language Models of Code",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-09-26-repository-level-prompt-generation-for-large-language-models-of-code/"}},{id:"summaries-on-the-dangers-of-stochastic-parrots-can-language-models-be-too-big",title:"On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-10-04-on-the-dangers-of-stochastic-parrots-can-language-models-be-too-big/"}},{id:"summaries-an-image-is-worth-one-word-personalizing-text-to-image-generation-using-textual-inversion",title:"An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-10-15-an-image-is-worth-one-word-personalizing-text-to-image-generation-using-textual-inversion/"}},{id:"summaries-instructpix2pix-learning-to-follow-image-editing-instructions",title:"InstructPix2Pix: Learning to Follow Image Editing Instructions",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-10-17-instructpix2pix-learning-to-follow-image-editing-instructions/"}},{id:"summaries-zero-shot-image-to-image-translation",title:"Zero-shot Image-to-Image Translation",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-10-22-zero-shot-image-to-image-translation/"}},{id:"summaries-universal-and-transferable-adversarial-attacks-on-aligned-language-models",title:"Universal and Transferable Adversarial Attacks on Aligned Language Models",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-10-31-universal-and-transferable-adversarial-attacks-on-aligned-language-models/"}},{id:"summaries-high-resolution-image-synthesis-with-latent-diffusion-models",title:"High-Resolution Image Synthesis with Latent Diffusion Models",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-11-03-high-resolution-image-synthesis-with-latent-diffusion-models/"}},{id:"summaries-large-language-models-for-software-engineering-survey-and-open-problems",title:"Large Language Models for Software Engineering: Survey and Open Problems",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-12-12-large-language-models-for-software-engineering-survey-and-open-problems/"}},{id:"summaries-matryoshka-representation-learning",title:"Matryoshka Representation Learning",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2024-02-19-matryoshka-representation-learning/"}},{id:"summaries-colbert-efficient-and-effective-passage-search-via-contextualized-late-interaction-over-bert",title:"ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2024-02-22-colbert-efficient-and-effective-passage-search-via-contextualized-late-interaction-over-bert/"}},{id:"summaries-dspy-compiling-declarative-language-model-calls-into-self-improving-pipelines",title:"DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2024-03-15-dspy-compiling-declarative-language-model-calls-into-self-improving-pipelines/"}},{id:"summaries-scaling-laws-for-neural-language-models",title:"Scaling Laws for Neural Language Models",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2024-03-23-scaling-laws-for-neural-language-models/"}},{id:"summaries-training-compute-optimal-large-language-models",title:"Training Compute-Optimal Large Language Models",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2024-03-23-training-compute-optimal-large-language-models/"}},{id:"summaries-longrope-extending-llm-context-window-beyond-2-million-tokens",title:"LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2024-03-27-longrope-extending-llm-context-window-beyond-2-million-tokens/"}},{id:"work-wordless-ink-on-paper",title:"Wordless Ink on Paper",description:"",section:"Work",handler:()=>{window.location.href="/work/art/"}},{id:"work-machine-learning-research-internship-iit-delhi",title:"Machine Learning Research Internship @ IIT-Delhi",description:"",section:"Work",handler:()=>{window.location.href="/work/iitd/"}},{id:"work-rese",title:"Rese.",description:"",section:"Work",handler:()=>{window.location.href="/work/iitr/"}},{id:"work-research-statement",title:"Research Statement",description:"",section:"Work",handler:()=>{window.location.href="/work/research-statement/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%68%72%69%73%68%69%6B%65%73%68.%68%73%6B@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=ogGhORwAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/hrishikeshh","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/hrishikesh-singh","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> </body> </html>