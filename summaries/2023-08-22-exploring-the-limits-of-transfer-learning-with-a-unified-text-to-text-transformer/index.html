<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer | Hrishi </title> <meta name="author" content="Hrishikesh Singh"> <meta name="description" content="Collections of my thoughts, work and notes. "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8C%90&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://hrishikeshh.github.io/summaries/2023-08-22-exploring-the-limits-of-transfer-learning-with-a-unified-text-to-text-transformer/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Hrishi </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item active"> <a class="nav-link" href="/summaries/">ML Paper Summaries <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Notes </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div style="display:none"> $$ \newcommand{\bone}{\mathbf{1}} \newcommand{\bbeta}{\mathbf{\beta}} \newcommand{\bdelta}{\mathbf{\delta}} \newcommand{\bepsilon}{\mathbf{\epsilon}} \newcommand{\blambda}{\mathbf{\lambda}} \newcommand{\bomega}{\mathbf{\omega}} \newcommand{\bpi}{\mathbf{\pi}} \newcommand{\bphi}{\mathbf{\phi}} \newcommand{\bvphi}{\mathbf{\varphi}} \newcommand{\bpsi}{\mathbf{\psi}} \newcommand{\bsigma}{\mathbf{\sigma}} \newcommand{\btheta}{\mathbf{\theta}} \newcommand{\btau}{\mathbf{\tau}} \newcommand{\ba}{\mathbf{a}} \newcommand{\bb}{\mathbf{b}} \newcommand{\bc}{\mathbf{c}} \newcommand{\bd}{\mathbf{d}} \newcommand{\be}{\mathbf{e}} \newcommand{\boldf}{\mathbf{f}} \newcommand{\bg}{\mathbf{g}} \newcommand{\bh}{\mathbf{h}} \newcommand{\bi}{\mathbf{i}} \newcommand{\bj}{\mathbf{j}} \newcommand{\bk}{\mathbf{k}} \newcommand{\bell}{\mathbf{\ell}} \newcommand{\bm}{\mathbf{m}} \newcommand{\bn}{\mathbf{n}} \newcommand{\bo}{\mathbf{o}} \newcommand{\bp}{\mathbf{p}} \newcommand{\bq}{\mathbf{q}} \newcommand{\br}{\mathbf{r}} \newcommand{\bs}{\mathbf{s}} \newcommand{\bt}{\mathbf{t}} \newcommand{\bu}{\mathbf{u}} \newcommand{\bv}{\mathbf{v}} \newcommand{\bw}{\mathbf{w}} \newcommand{\bx}{\mathbf{x}} \newcommand{\by}{\mathbf{y}} \newcommand{\bz}{\mathbf{z}} \newcommand{\bA}{\mathbf{A}} \newcommand{\bB}{\mathbf{B}} \newcommand{\bC}{\mathbf{C}} \newcommand{\bD}{\mathbf{D}} \newcommand{\bE}{\mathbf{E}} \newcommand{\bF}{\mathbf{F}} \newcommand{\bG}{\mathbf{G}} \newcommand{\bH}{\mathbf{H}} \newcommand{\bI}{\mathbf{I}} \newcommand{\bJ}{\mathbf{J}} \newcommand{\bK}{\mathbf{K}} \newcommand{\bL}{\mathbf{L}} \newcommand{\bM}{\mathbf{M}} \newcommand{\bN}{\mathbf{N}} \newcommand{\bP}{\mathbf{P}} \newcommand{\bQ}{\mathbf{Q}} \newcommand{\bR}{\mathbf{R}} \newcommand{\bS}{\mathbf{S}} \newcommand{\bT}{\mathbf{T}} \newcommand{\bU}{\mathbf{U}} \newcommand{\bV}{\mathbf{V}} \newcommand{\bW}{\mathbf{W}} \newcommand{\bX}{\mathbf{X}} \newcommand{\bY}{\mathbf{Y}} \newcommand{\bZ}{\mathbf{Z}} \newcommand{\calA}{\mathcal{A}} \newcommand{\calB}{\mathcal{B}} \newcommand{\calC}{\mathcal{C}} \newcommand{\calD}{\mathcal{D}} \newcommand{\calE}{\mathcal{E}} \newcommand{\calF}{\mathcal{F}} \newcommand{\calG}{\mathcal{G}} \newcommand{\calH}{\mathcal{H}} \newcommand{\calI}{\mathcal{I}} \newcommand{\calJ}{\mathcal{J}} \newcommand{\calK}{\mathcal{K}} \newcommand{\calL}{\mathcal{L}} \newcommand{\calM}{\mathcal{M}} \newcommand{\calN}{\mathcal{N}} \newcommand{\calO}{\mathcal{O}} \newcommand{\calP}{\mathcal{P}} \newcommand{\calQ}{\mathcal{Q}} \newcommand{\calR}{\mathcal{R}} \newcommand{\calS}{\mathcal{S}} \newcommand{\calT}{\mathcal{T}} \newcommand{\calU}{\mathcal{U}} \newcommand{\calV}{\mathcal{V}} \newcommand{\calW}{\mathcal{W}} \newcommand{\calX}{\mathcal{X}} \newcommand{\calY}{\mathcal{Y}} \newcommand{\calZ}{\mathcal{Z}} \newcommand{\R}{\mathbb{R}} \newcommand{\C}{\mathbb{C}} \newcommand{\N}{\mathbb{N}} \newcommand{\Z}{\mathbb{Z}} \newcommand{\F}{\mathbb{F}} \newcommand{\Q}{\mathbb{Q}} \DeclareMathOperator*{\argmax}{arg\,max} \DeclareMathOperator*{\argmin}{arg\,min} \newcommand{\nnz}[1]{\mbox{nnz}(#1)} \newcommand{\dotprod}[2]{\langle #1, #2 \rangle} \newcommand{\ignore}[1]{} \let\Pr\relax \DeclareMathOperator*{\Pr}{\mathbf{Pr}} \newcommand{\E}{\mathbb{E}} \DeclareMathOperator*{\Ex}{\mathbf{E}} \DeclareMathOperator*{\Var}{\mathbf{Var}} \DeclareMathOperator*{\Cov}{\mathbf{Cov}} \DeclareMathOperator*{\stddev}{\mathbf{stddev}} \DeclareMathOperator*{\avg}{avg} \DeclareMathOperator{\poly}{poly} \DeclareMathOperator{\polylog}{polylog} \DeclareMathOperator{\size}{size} \DeclareMathOperator{\sgn}{sgn} \DeclareMathOperator{\dist}{dist} \DeclareMathOperator{\vol}{vol} \DeclareMathOperator{\spn}{span} \DeclareMathOperator{\supp}{supp} \DeclareMathOperator{\tr}{tr} \DeclareMathOperator{\Tr}{Tr} \DeclareMathOperator{\codim}{codim} \DeclareMathOperator{\diag}{diag} \newcommand{\PTIME}{\mathsf{P}} \newcommand{\LOGSPACE}{\mathsf{L}} \newcommand{\ZPP}{\mathsf{ZPP}} \newcommand{\RP}{\mathsf{RP}} \newcommand{\BPP}{\mathsf{BPP}} \newcommand{\P}{\mathsf{P}} \newcommand{\NP}{\mathsf{NP}} \newcommand{\TC}{\mathsf{TC}} \newcommand{\AC}{\mathsf{AC}} \newcommand{\SC}{\mathsf{SC}} \newcommand{\SZK}{\mathsf{SZK}} \newcommand{\AM}{\mathsf{AM}} \newcommand{\IP}{\mathsf{IP}} \newcommand{\PSPACE}{\mathsf{PSPACE}} \newcommand{\EXP}{\mathsf{EXP}} \newcommand{\MIP}{\mathsf{MIP}} \newcommand{\NEXP}{\mathsf{NEXP}} \newcommand{\BQP}{\mathsf{BQP}} \newcommand{\distP}{\mathsf{dist\textbf{P}}} \newcommand{\distNP}{\mathsf{dist\textbf{NP}}} \newcommand{\eps}{\epsilon} \newcommand{\lam}{\lambda} \newcommand{\dleta}{\delta} \newcommand{\simga}{\sigma} \newcommand{\vphi}{\varphi} \newcommand{\la}{\langle} \newcommand{\ra}{\rangle} \newcommand{\wt}[1]{\widetilde{#1}} \newcommand{\wh}[1]{\widehat{#1}} \newcommand{\ol}[1]{\overline{#1}} \newcommand{\ul}[1]{\underline{#1}} \newcommand{\ot}{\otimes} \newcommand{\zo}{\{0,1\}} \newcommand{\co}{:} %\newcommand{\co}{\colon} \newcommand{\bdry}{\partial} \newcommand{\grad}{\nabla} \newcommand{\transp}{^\intercal} \newcommand{\inv}{^{-1}} \newcommand{\symmdiff}{\triangle} \newcommand{\symdiff}{\symmdiff} \newcommand{\half}{\tfrac{1}{2}} \newcommand{\bbone}{\mathbbm 1} \newcommand{\Id}{\bbone} \newcommand{\SAT}{\mathsf{SAT}} \newcommand{\bcalG}{\boldsymbol{\calG}} \newcommand{\calbG}{\bcalG} \newcommand{\bcalX}{\boldsymbol{\calX}} \newcommand{\calbX}{\bcalX} \newcommand{\bcalY}{\boldsymbol{\calY}} \newcommand{\calbY}{\bcalY} \newcommand{\bcalZ}{\boldsymbol{\calZ}} \newcommand{\calbZ}{\bcalZ} $$ </div> <div class="publications"> <h2 class="bibliography">2019</h2> <ol class="bibliography"><li> <div class="row no-count"> <div id="1910.10683v3" class="col-sm-12"> <div class="title"><h2> <a href="http://arxiv.org/abs/1910.10683v3" rel="external nofollow noopener" target="_blank"> Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer </a> </h2></div> <div class="author"> Colin Raffel, Noam Shazeer, Adam Roberts, and <span class="more-authors" title="click to view 6 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '6 more authors' ? 'Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J. Liu' : '6 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">6 more authors</span> </div> <div class="periodical"> <em></em> Oct 2019 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/1910.10683v3" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/1910.10683v3.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <h3>Paper Abstract</h3> <div class="abstract"> <p>Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts all text-based language problems into a text-to-text format. Our systematic study compares pre-training objectives, architectures, unlabeled data sets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new “Colossal Clean Crawled Corpus”, we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our data set, pre-trained models, and code.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">1910.10683v3</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Exploring the Limits of Transfer Learning with a Unified Text-to-Text
                     Transformer}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{1910.10683v3}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.LG}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://arxiv.org/abs/1910.10683v3}</span><span class="p">,</span>
  <span class="na">file</span> <span class="p">=</span> <span class="s">{1910.10683v3.pdf}</span><span class="p">,</span>
  <span class="na">eprintnover</span> <span class="p">=</span> <span class="s">{1910.10683}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> <div class="post"> <article class="post-content"> <div id="markdown-content"> <h3 id="three-important-things">Three Important Things</h3> <p>The authors state that the goal of the paper is not to introduce any novel ideas, but rather to push the limits of the current known architecture and see what results can be achieved.</p> <h4 id="1-text-to-text-transfer-transformer-t5">1. Text-to-Text Transfer Transformer (T5)</h4> <p>The <strong>T</strong>ext-<strong>t</strong>o-<strong>T</strong>ext <strong>T</strong>ransfer <strong>T</strong>ransformer (T5) model has an encoder-decoder architecture. The author takes the view that all problems can be viewed as a text-to-text problem, and therefore this architecture can generalize to all NLP tasks.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/summaries/t5-text-to-text-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/summaries/t5-text-to-text-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/summaries/t5-text-to-text-1400.webp"></source> <img src="/assets/img/summaries/t5-text-to-text.webp" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>The encoder has a “fully-visible” attention mask, meaning that the attention mechanism can attend to any position in the input. On the other hand, the decoder has a “causal” attention mask, and can only attend to tokens \(j &lt; i\) when it is trying to compute the token at position \(i\), to prevent it from seeing the future inputs which would otherwise trivialize the training process.</p> <p>The decoder produces the output in an autoregressive manner, meaning that it produces one output token at a time, and then concatenates this output to the input and repeats the process until the end of sequence token is output.</p> <h4 id="2-prefix-lm">2. Prefix LM</h4> <p>While the best-performing T5 variant has an encoder-decoder architecture (which is the standard architecture T5 would refer to), the authors also experimented with and performed comparisons against the language model and prefix LM architectures.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/summaries/t5-arch-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/summaries/t5-arch-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/summaries/t5-arch-1400.webp"></source> <img src="/assets/img/summaries/t5-arch.webp" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>The goal of the language model architecture is to predict token \(i+1\), given all tokens up to \(i\). A major downside of this is that the model’s representation of the \(j\)th entry of the input can only depend on all tokens less than \(j\).</p> <p>However, for text-to-text tasks, it could be possible that there is a lot of useful context on the right of \(j\) which is still in the input prompt that is relevant. For instance, for English to German translation, if the input prompt is <code class="language-plaintext highlighter-rouge">translate English to German: That is good. target: </code>, then it makes sense for the tokens at the start to also be able to attend to future tokens in the prompt.</p> <p>The prefix LM architecture addresses this limitation by allowing for fully-visible masking in the prefix portion of the input, and therefore the representation of all tokens can attend to every other token in the input.</p> <p>The following table shows the results of comparisons between the three architectures, with the encoder-decoder performing the best, and the language model the worst.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/summaries/t5-comparison-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/summaries/t5-comparison-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/summaries/t5-comparison-1400.webp"></source> <img src="/assets/img/summaries/t5-comparison.webp" class="z-depth-1 center" width="600px" height="auto" style="object-fit: cover" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h4 id="3-colossal-clean-crawled-corpus">3. Colossal Clean Crawled Corpus</h4> <p>The Common Crawl is a dataset of text data scraped from the web, with around 20TB of data extracted each month. However, most of the text scraped is not natural language, and is instead web boilerplate code, error messages, gibberish, etc.</p> <p>The authors cleaned up the Common Crawl to obtain the <strong>C</strong>olossal <strong>C</strong>lean <strong>C</strong>rawled <strong>C</strong>orpus (C4), by using the following heuristics:</p> <ul> <li>Keeping only text terminated by punctuation</li> <li>Discard pages with &lt; 5 sentences</li> <li>Keeping lines with at least 3 words</li> <li>Discarding pages with offensive words</li> <li>Removing any lines containing the word Javascript</li> <li>Discarding any pages with “lorem ipsum” text</li> <li>Removing pages containing a curly bracket <code class="language-plaintext highlighter-rouge">{</code>, as it usually indicates code</li> <li>Deduplicating the data by removing any three-sentence span that occurs in the dataset more than once, to just having it show up once</li> </ul> <p>The T5 transformer was then trained on C4 for \(2^{19} = 524,288\) steps with a max sequence length of 512, and a batch size of 128 sequences.</p> <h3 id="most-glaring-deficiency">Most Glaring Deficiency</h3> <p>The method used to clean the C4 corpus feels somewhat arbitrary and perhaps still very much incomplete. Due to the importance of data in the performance of the model, it would have also been helpful to have trained on the Common Crawl as well to perform an ablation study on whether C4 resulted in better performance.</p> <h3 id="conclusions-for-future-work">Conclusions for Future Work</h3> <p>The text-to-text approach for modeling language tasks is a promising avenue to generalize task-specific architectures, and could become a future default approach due to its simplicity and generalizability.</p> <p>The authors also found that pushing the limits of the architecture by a very large 11-billion parameter model resulted in state-of-the-art performance across many tasks, showing that scale can result in performance gains.</p> </div> </article> <p class="post-meta">Written 2023</p> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Hrishikesh Singh. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script> </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let theme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===theme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=document.querySelector(".navbar-collapse");e.classList.contains("show")&&e.classList.remove("show"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"Publications",description:"Papers under review/submission and pre-prints are available upon request.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"Projects",description:"",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-ml-paper-summaries",title:"ML Paper Summaries",description:"",section:"Navigation",handler:()=>{window.location.href="/summaries/"}},{id:"nav-cv",title:"CV",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"nav-notes",title:"Notes",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"post-sample-test",title:"Sample Test",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/sample/"}},{id:"post-reading",title:"Reading",description:"A personal reading list.",section:"Posts",handler:()=>{window.location.href="/blog/2024/library/"}},{id:"post-research-my-two-cents",title:"Research: My two cents",description:"These are the nuggets of wisdom I found in the corners of internet while doing my own stint of research. Enjoy.",section:"Posts",handler:()=>{window.location.href="/blog/2024/research/"}},{id:"post-how-to-write-a-review-paper",title:"How to write a review paper?",description:"A walk through guide for structuring your research",section:"Posts",handler:()=>{window.location.href="/blog/2024/review-paper/"}},{id:"post-dsa-templates-java",title:"DSA templates (Java)",description:"These are java code templates based on most common datastructures and algorithm problems.",section:"Posts",handler:()=>{window.location.href="/blog/2024/java-template/"}},{id:"post-pythonic-templates",title:"Pythonic Templates",description:"A collection of code templates for common patterns in data structures and algorithms",section:"Posts",handler:()=>{window.location.href="/blog/2024/python-template/"}},{id:"post-dynamic-programming",title:"Dynamic Programming",description:"Setting up the foundations of Dynamic programming along with a generic framework to disintegrate the problem into components",section:"Posts",handler:()=>{window.location.href="/blog/2024/dynamic-prog/"}},{id:"post-deep-learning",title:"Deep Learning",description:"A curated list of resources for a comprehensive understanding of deep learning.  ",section:"Posts",handler:()=>{window.location.href="/blog/2024/deep-learning/"}},{id:"post-the-beauty-of-latex",title:"The Beauty of LaTeX",description:"When was the first time you had to use LaTeX? If you are like most people, it was probably suddenly forced upon you during your first math or CS class where you had to start writing proofs, with minimal guidance on how to get started. Unfortunately, this meant that while many people have good operational knowledge of LaTeX, there are still many small mistakes and best practices which are not followed, which are not corrected by TAs as they are either not severe enough to warrant a note, or perhaps even the TAs themselves are not aware of them.  In this post, we cover some common mistakes that are made by LaTeX practitioners (even in heavily cited papers), and how to address them.",section:"Posts",handler:()=>{window.location.href="/blog/2023/latex/"}},{id:"post-java-collections",title:"Java Collections",description:"A brief reference for Java collections usecases.",section:"Posts",handler:()=>{window.location.href="/blog/2023/java-collection/"}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"posts-java-collections",title:"Java Collections",description:"A brief reference for Java collections usecases.",section:"Posts",handler:()=>{window.location.href="/blog/2023/java-collection/"}},{id:"posts-the-beauty-of-latex",title:"The Beauty of LaTeX",description:"When was the first time you had to use LaTeX? If you are like most people, it was probably suddenly forced upon you during your first math or CS class where you had to start writing proofs, with minimal guidance on how to get started. Unfortunately, this meant that while many people have good operational knowledge of LaTeX, there are still many small mistakes and best practices which are not followed, which are not corrected by TAs as they are either not severe enough to warrant a note, or perhaps even the TAs themselves are not aware of them.  In this post, we cover some common mistakes that are made by LaTeX practitioners (even in heavily cited papers), and how to address them.",section:"Posts",handler:()=>{window.location.href="/blog/2023/latex/"}},{id:"posts-deep-learning",title:"Deep Learning",description:"A curated list of resources for a comprehensive understanding of deep learning.  ",section:"Posts",handler:()=>{window.location.href="/blog/2024/deep-learning/"}},{id:"posts-dynamic-programming",title:"Dynamic Programming",description:"Setting up the foundations of Dynamic programming along with a generic framework to disintegrate the problem into components",section:"Posts",handler:()=>{window.location.href="/blog/2024/dynamic-prog/"}},{id:"posts-pythonic-templates",title:"Pythonic Templates",description:"A collection of code templates for common patterns in data structures and algorithms",section:"Posts",handler:()=>{window.location.href="/blog/2024/python-template/"}},{id:"posts-dsa-templates-java",title:"DSA templates (Java)",description:"These are java code templates based on most common datastructures and algorithm problems.",section:"Posts",handler:()=>{window.location.href="/blog/2024/java-template/"}},{id:"posts-how-to-write-a-review-paper",title:"How to write a review paper?",description:"A walk through guide for structuring your research",section:"Posts",handler:()=>{window.location.href="/blog/2024/review-paper/"}},{id:"posts-research-my-two-cents",title:"Research: My two cents",description:"These are the nuggets of wisdom I found in the corners of internet while doing my own stint of research. Enjoy.",section:"Posts",handler:()=>{window.location.href="/blog/2024/research/"}},{id:"posts-reading",title:"Reading",description:"A personal reading list.",section:"Posts",handler:()=>{window.location.href="/blog/2024/library/"}},{id:"posts-sample-test",title:"Sample Test",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/sample/"}},{id:"projects-deepglobe-land-cover-classification",title:"DeepGlobe Land Cover Classification",description:"Classifying land coverage using remote sensing satelite data.",section:"Projects",handler:()=>{window.location.href="/projects/DeepGlobe/"}},{id:"projects-gitlet",title:"GitLet",description:"A version control with core functionalities of git, written in Java.",section:"Projects",handler:()=>{window.location.href="/projects/GitLet/"}},{id:"projects-blight-detection",title:"Blight Detection",description:"Assisting the farmers by potato blight grade detection.",section:"Projects",handler:()=>{window.location.href="/projects/blight/"}},{id:"projects-driver-drowsiness-detection-system",title:"Driver Drowsiness Detection System",description:"Determining the distracted or drowsiness state of drivers based on live facial features.",section:"Projects",handler:()=>{window.location.href="/projects/ddds/"}},{id:"projects-classifier-from-scratch",title:"Classifier from Scratch",description:"Designing a linear classifier from scratch.",section:"Projects",handler:()=>{window.location.href="/projects/lin-class/"}},{id:"projects-market-orderbook",title:"Market Orderbook",description:"Simulation",section:"Projects",handler:()=>{window.location.href="/projects/market/"}},{id:"projects-know-your-rice",title:"Know your Rice \ud83c\udf5a",description:"Rice classification using Deep learning.",section:"Projects",handler:()=>{window.location.href="/projects/rice/"}},{id:"projects-vinci",title:"Vinci",description:"A Java Genetic Algorithm implementation with a focus on ease of use and extensibility.",section:"Projects",handler:()=>{window.location.href="/projects/vinci/"}},{id:"summaries-deep-contextualized-word-representations-elmo",title:"Deep contextualized word representations (ELMo)",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-02-deep-contextualized-word-representations/"}},{id:"summaries-foundations-and-trends-in-multimodal-machine-learning-principles-challenges-and-open-questions",title:"Foundations and Trends in Multimodal Machine Learning: Principles,  Challenges, and Open Questions",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-02-foundations-and-trends-in-multimodal-machine-learning-principles--challenges-and-open-questions/"}},{id:"summaries-bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding",title:"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-03-bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding/"}},{id:"summaries-chain-of-thought-prompting-elicits-reasoning-in-large-language-models",title:"Chain-of-Thought Prompting Elicits Reasoning in Large Language Models",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-03-chain-of-thought-prompting-elicits-reasoning-in-large-language-models/"}},{id:"summaries-training-language-models-to-follow-instructions-with-human-feedback-instructgpt",title:"Training language models to follow instructions with human feedback (InstructGPT)",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-05-training-language-models-to-follow-instructions-with-human-feedback/"}},{id:"summaries-evaluating-large-language-models-trained-on-code-codex",title:"Evaluating Large Language Models Trained on Code (Codex)",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-06-evaluating-large-language-models-trained-on-code/"}},{id:"summaries-bart-denoising-sequence-to-sequence-pre-training-for-natural-language-generation-translation-and-comprehension",title:"BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-09-bart-denoising-sequence-to-sequence-pre-training-for-natural-language-generation-translation-and-comprehension/"}},{id:"summaries-dense-passage-retrieval-for-open-domain-question-answering",title:"Dense Passage Retrieval for Open-Domain Question Answering",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-10-dense-passage-retrieval-for-open-domain-question-answering/"}},{id:"summaries-language-models-are-unsupervised-multitask-learners-gpt-2",title:"Language Models are Unsupervised Multitask Learners (GPT-2)",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-10-language-models-are-unsupervised-multitask-learners/"}},{id:"summaries-simple-synthetic-data-reduces-sycophancy-in-large-language-models",title:"Simple synthetic data reduces sycophancy in large language models",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-10-simple-synthetic-data-reduces-sycophancy-in-large-language-models/"}},{id:"summaries-generative-agents-interactive-simulacra-of-human-behavior",title:"Generative Agents: Interactive Simulacra of Human Behavior",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-11-generative-agents-interactive-simulacra-of-human-behavior/"}},{id:"summaries-improving-language-understanding-by-generative-pre-training-gpt",title:"Improving Language Understanding by Generative Pre-Training (GPT)",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-11-improving-language-understanding-by-generative-pre-training/"}},{id:"summaries-metagpt-meta-programming-for-multi-agent-collaborative-framework",title:"MetaGPT: Meta Programming for Multi-Agent Collaborative Framework",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-11-metagpt-meta-programming-for-multi-agent-collaborative-framework/"}},{id:"summaries-transformers-in-speech-processing-a-survey",title:"Transformers in Speech Processing: A Survey",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-19-transformers-in-speech-processing-a-survey/"}},{id:"summaries-accurate-detection-of-wake-word-start-and-end-using-a-cnn",title:"Accurate Detection of Wake Word Start and End Using a CNN",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-22-accurate-detection-of-wake-word-start-and-end-using-a-cnn/"}},{id:"summaries-exploring-the-limits-of-transfer-learning-with-a-unified-text-to-text-transformer",title:"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-22-exploring-the-limits-of-transfer-learning-with-a-unified-text-to-text-transformer/"}},{id:"summaries-efficiently-modeling-long-sequences-with-structured-state-spaces",title:"Efficiently Modeling Long Sequences with Structured State Spaces",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-25-efficiently-modeling-long-sequences-with-structured-state-spaces/"}},{id:"summaries-a-watermark-for-large-language-models",title:"A Watermark for Large Language Models",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-27-a-watermark-for-large-language-models/"}},{id:"summaries-extracting-training-data-from-large-language-models",title:"Extracting Training Data from Large Language Models",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-08-29-extracting-training-data-from-large-language-models/"}},{id:"summaries-loss-landscapes-and-optimization-in-over-parameterized-non-linear-systems-and-neural-networks",title:"Loss Landscapes and Optimization in Over-Parameterized Non-Linear Systems and Neural Networks",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-09-04-loss-landscapes-and-optimization-in-over-parameterized-non-linear-systems-and-neural-networks/"}},{id:"summaries-gradient-descent-provably-optimizes-over-parameterized-neural-networks",title:"Gradient Descent Provably Optimizes Over-parameterized Neural Networks",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-09-07-gradient-descent-provably-optimizes-over-parameterized-neural-networks/"}},{id:"summaries-the-implicit-bias-of-gradient-descent-on-separable-data",title:"The Implicit Bias of Gradient Descent on Separable Data",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-09-09-the-implicit-bias-of-gradient-descent-on-separable-data/"}},{id:"summaries-understanding-deep-learning-requires-rethinking-generalization",title:"Understanding Deep Learning Requires Rethinking Generalization",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-09-10-understanding-deep-learning-requires-rethinking-generalization/"}},{id:"summaries-calibrate-before-use-improving-few-shot-performance-of-language-models",title:"Calibrate Before Use: Improving Few-Shot Performance of Language Models",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-09-23-calibrate-before-use-improving-few-shot-performance-of-language-models/"}},{id:"summaries-rethinking-the-role-of-demonstrations-what-makes-in-context-learning-work",title:"Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-09-24-rethinking-the-role-of-demonstrations-what-makes-in-context-learning-work/"}},{id:"summaries-repository-level-prompt-generation-for-large-language-models-of-code",title:"Repository-Level Prompt Generation for Large Language Models of Code",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-09-26-repository-level-prompt-generation-for-large-language-models-of-code/"}},{id:"summaries-on-the-dangers-of-stochastic-parrots-can-language-models-be-too-big",title:"On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-10-04-on-the-dangers-of-stochastic-parrots-can-language-models-be-too-big/"}},{id:"summaries-an-image-is-worth-one-word-personalizing-text-to-image-generation-using-textual-inversion",title:"An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-10-15-an-image-is-worth-one-word-personalizing-text-to-image-generation-using-textual-inversion/"}},{id:"summaries-instructpix2pix-learning-to-follow-image-editing-instructions",title:"InstructPix2Pix: Learning to Follow Image Editing Instructions",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-10-17-instructpix2pix-learning-to-follow-image-editing-instructions/"}},{id:"summaries-zero-shot-image-to-image-translation",title:"Zero-shot Image-to-Image Translation",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-10-22-zero-shot-image-to-image-translation/"}},{id:"summaries-universal-and-transferable-adversarial-attacks-on-aligned-language-models",title:"Universal and Transferable Adversarial Attacks on Aligned Language Models",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-10-31-universal-and-transferable-adversarial-attacks-on-aligned-language-models/"}},{id:"summaries-high-resolution-image-synthesis-with-latent-diffusion-models",title:"High-Resolution Image Synthesis with Latent Diffusion Models",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-11-03-high-resolution-image-synthesis-with-latent-diffusion-models/"}},{id:"summaries-large-language-models-for-software-engineering-survey-and-open-problems",title:"Large Language Models for Software Engineering: Survey and Open Problems",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2023-12-12-large-language-models-for-software-engineering-survey-and-open-problems/"}},{id:"summaries-matryoshka-representation-learning",title:"Matryoshka Representation Learning",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2024-02-19-matryoshka-representation-learning/"}},{id:"summaries-colbert-efficient-and-effective-passage-search-via-contextualized-late-interaction-over-bert",title:"ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2024-02-22-colbert-efficient-and-effective-passage-search-via-contextualized-late-interaction-over-bert/"}},{id:"summaries-dspy-compiling-declarative-language-model-calls-into-self-improving-pipelines",title:"DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2024-03-15-dspy-compiling-declarative-language-model-calls-into-self-improving-pipelines/"}},{id:"summaries-scaling-laws-for-neural-language-models",title:"Scaling Laws for Neural Language Models",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2024-03-23-scaling-laws-for-neural-language-models/"}},{id:"summaries-training-compute-optimal-large-language-models",title:"Training Compute-Optimal Large Language Models",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2024-03-23-training-compute-optimal-large-language-models/"}},{id:"summaries-longrope-extending-llm-context-window-beyond-2-million-tokens",title:"LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens",description:"",section:"Summaries",handler:()=>{window.location.href="/summaries/2024-03-27-longrope-extending-llm-context-window-beyond-2-million-tokens/"}},{id:"work-wordless-ink-on-paper",title:"Wordless Ink on Paper",description:"",section:"Work",handler:()=>{window.location.href="/work/art/"}},{id:"work-machine-learning-research-internship-iit-delhi",title:"Machine Learning Research Internship @ IIT-Delhi",description:"",section:"Work",handler:()=>{window.location.href="/work/iitd/"}},{id:"work-rese",title:"Rese.",description:"",section:"Work",handler:()=>{window.location.href="/work/iitr/"}},{id:"work-research-statement",title:"Research Statement",description:"",section:"Work",handler:()=>{window.location.href="/work/research-statement/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%68%72%69%73%68%69%6B%65%73%68.%68%73%6B@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=ogGhORwAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/hrishikeshh","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/hrishikesh-singh","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> </body> </html>